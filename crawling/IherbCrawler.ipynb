{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23febbf1",
   "metadata": {},
   "source": [
    "# Iherb Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fc791",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install selenium webdriver-manager ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 로드\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exception 클래스를 상속받은 InputError를 설명하는 클래스 생성 > url이 입력 되지 않았을경우 raise\n",
    "class InputError(Exception):\n",
    "    \"\"\"Exception raised for errors in the input.\n",
    "\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, expression=None, message=None):\n",
    "        if not expression or not message:\n",
    "            print('empty url: URL을 전달해주세요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f43ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IherbCrawler():\n",
    "    def __init__(self, url: str):\n",
    "        if len(url) == 0:\n",
    "            raise InputError()\n",
    "        self.url = url\n",
    "\n",
    "\n",
    "    def make_pagenation(self, start_nums: int, last_nums: int):\n",
    "        '''\n",
    "        ## url의 {page_nums}로 된 부분을 숫자 형식에 맞게 치환하는 함수\\n\n",
    "        args:\\n\n",
    "        start_nums: 페이지네이션 된 페이지의 시작 페이지\\n\n",
    "        last_nums: 원하는 페이지의 갯수\\n\n",
    "        return: pagination된 url list\n",
    "        '''\n",
    "        if start_nums <= 0 or last_nums <= 0:\n",
    "            raise ValueError\n",
    "        \n",
    "        url_list = []\n",
    "        for i in range(start_nums, start_nums+last_nums):\n",
    "            url = self.url.replace('page_nums', str(i))\n",
    "            url_list.append(url)\n",
    "\n",
    "        return url_list\n",
    "    \n",
    "    # driver를 연 후 페이지네이션처리하여 접근하면 cloudflare로 인해 접근이 막힌다. 따라서 page별 driver를 재생성하여 데이터에 접근한다\n",
    "    def get_crawling_data(self, url_list: list, class_dict: dict):\n",
    "        '''\n",
    "        ### url_list를 전달 받고 이를 class_dict에 작성 되어 있는 tag의 class_name을 찾아 데이터를 처리 후 리스트로 반환하는 함수\n",
    "        '''\n",
    "        data_list = []\n",
    "        rank = 1\n",
    "        for url in url_list:\n",
    "            with webdriver.Chrome(service=Service(ChromeDriverManager().install())) as crawler:\n",
    "                page_data = []\n",
    "                crawler.get(url=url)\n",
    "                crawler.implicitly_wait(5)\n",
    "                display_name_list = crawler.find_elements(By.CLASS_NAME, class_dict.get(\"tag_class_name1\"))\n",
    "                original_price_list = crawler.find_elements(By.CLASS_NAME, class_dict.get(\"tag_class_name2\"))\n",
    "                original_price_list.pop(0)\n",
    "                image_url_list = crawler.find_elements(By.CLASS_NAME, class_dict.get(\"img_class_name\"))\n",
    "\n",
    "                # 추출된 데이터를 json 형식에 맞게 치환하여 data_list에 담는 작업\n",
    "                num = rank\n",
    "                for i in range(len(image_url_list)):\n",
    "                    data = {\"shop_name\": \"iHerb\"}\n",
    "                    data.update({\"display_name\": ''.join(display_name_list[i].text.split(',')[1:])[1:]})\n",
    "                    data.update({\"brand_name\": display_name_list[i].text.split(',')[0]})\n",
    "                    data.update({\"original_price\": int(original_price_list[i].text.replace(\"₩\", \"\").replace(\",\", \"\"))})\n",
    "                    data.update({\"sale_price\": int(original_price_list[i].text.replace(\"₩\", \"\").replace(\",\", \"\"))})\n",
    "                    data.update({\"image_url\": image_url_list[i].find_element(By.TAG_NAME, \"img\").get_attribute(\"src\")})\n",
    "                    data.update({\"rank\": num+i})\n",
    "                    page_data.append(data)\n",
    "                    rank = num+i\n",
    "\n",
    "                data_list.append(page_data) \n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5991c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_nums로 페이지네이션 부분을 치환하여 url로 저장한다\n",
    "url = \"https://kr.iherb.com/c/supplements?_gl=1*rdcxv1*_up*MQ..&gclid=CjwKCAjwuePGBhBZEiwAIGCVS72VuNgVm_QhdDVM8zmaM3LQeXlCXC6gyYOYVj6nOOZJhI4bSlNUbhoC7mkQAvD_BwE&gclsrc=aw.ds&soa=true&sr=2&p=page_nums\"\n",
    "\n",
    "\n",
    "crawler = IherbCrawler(url=url)\n",
    "urls = crawler.make_pagenation(1, 3)\n",
    "\n",
    "# 데이터 추출을 원하는 tag의 class name을 딕셔너리 형식으로 작성한다.\n",
    "class_dict = {\"tag_class_name1\": \"product-title\", \"tag_class_name2\": \"price \", \"img_class_name\": \"product-image\"}\n",
    "crawling_data = crawler.get_crawling_data(urls, class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 데이터를 토대로 .json 파일로 저장함\n",
    "with open(\"data.json\", 'r+', encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\")  # JSON 배열 시작\n",
    "    for page_data in crawling_data:\n",
    "        for i, data in enumerate(page_data):\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "            f.write(\",\")\n",
    "    pos = f.tell() - 1\n",
    "    f.truncate(pos)\n",
    "    f.write(\"]\")  # JSON 배열 끝"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
